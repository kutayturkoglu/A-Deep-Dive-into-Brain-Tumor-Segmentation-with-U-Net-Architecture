{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "from src.Utils import plot_data, create_mask, plot_mask, compare_folders\n",
    "from src.CustomDataset import CustomDataset\n",
    "from models import UNet\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from loss import dice_loss\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dir = \"data/valid\"\n",
    "with open (\"data/valid/_annotations.coco.json\", \"r\") as f:\n",
    "    annotations = json.load(f)\n",
    "all_images = [os.path.join(val_dir, f) for f in os.listdir(val_dir) if f.endswith(\".jpg\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image_files = random.sample(all_images,2)\n",
    "plot_data(random_image_files, annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in (os.listdir(\"data\")):\n",
    "    original_image_dir = f\"data/{part}\"\n",
    "    json_file = f\"data/{part}/_annotations.coco.json\"\n",
    "    mask_dir = f\"data1/{part}/masks\"\n",
    "    img_dir = f\"data1/{part}/images\"\n",
    "    create_mask(json_file,mask_dir,img_dir,original_image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mask(\"data1/valid/masks\", \"data1/valid/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_folders(\"data1/valid/masks\", \"data1/valid/images\")\n",
    "compare_folders(\"data1/test/masks\", \"data1/test/images\")\n",
    "compare_folders(\"data1/train/masks\", \"data1/train/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data1/train\"\n",
    "test_path = \"data1/test\"\n",
    "val_path = \"data1/valid\"\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229]),  # Assuming grayscale images\n",
    "    transforms.Lambda(lambda x: x.clamp(0, 1))\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(train_path, transform=image_transform)\n",
    "valid_dataset = CustomDataset(val_path, transform=image_transform)\n",
    "test_dataset = CustomDataset(test_path, transform=image_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x.shape , y.shape , type(x) , type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = UNet.UNet().to(device)\n",
    "loss_fn = dice_loss.DiceLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epoches = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    # Iterate over the first 100 data points\n",
    "    for i, (img, label) in enumerate(train_loader):\n",
    "\n",
    "        \n",
    "        img, label = img.to(device), label.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(img)\n",
    "        loss = loss_fn(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct_predictions += (predicted == label).sum().item()\n",
    "        total_samples += label.size(0)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (i + 1) % 100 == 0:  # print every 100 mini-batches \n",
    "            print(f'[{epoch + 1}, {i + 1}] loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # Calculate accuracy after processing all batches for the epoch\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    print(f'Accuracy after epoch {epoch + 1}: {accuracy * 100:.2f}%')\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
